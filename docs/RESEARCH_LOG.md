# 🔬 연구 개발 일지

이 문서에는 프로젝트의 모든 실험 과정, 결과, 그리고 결정 사항이 시간 순으로 기록됩니다.

---


### 2025-06-08: 커스텀 ConvNeXt 백본 모델 초기 학습 및 결과 분석

-   **가설/목표**:
    -   표준 ConvNeXt 백본 대신, 각 Stage별로 다양한 커널 크기(Stage1: 3x3, Stage2: 5x5)를 적용하고, 특히 Stage3에서 3x3과 7x7 DWConv를 병렬로 처리 후 어텐션으로 융합하는(`DWConv3x3_7x7_Attn`) 구조를 도입하면, 다양한 크기의 객체 특징을 더 효과적으로 포착하여 전반적인 탐지 성능이 향상될 것이다.
-   **변경 사항**:
    -   `src/train.py`에 `ConvNeXt-Tiny`를 기반으로 한 커스텀 백본, ASPP, FPN, AF-Head로 구성된 전체 모델 파이프라인을 구축.
    -   `modify_convnext_backbone` 함수를 통해 Stage 1, 2, 3의 DWConv를 의도한 대로 커스텀 모듈로 교체.
-   **결과**:
    -   20 에폭 학습 후 BDD100K 검증 데이터셋 기준 **mAP@0.5 = 0.18** 이라는 상당히 낮은 결과를 기록함.
    -   (기존 ConvNeXt 기반 객체 탐지 모델을 직접 훈련한 경험이 없어, 제안한 구조의 성능 향상 여부를 직접 비교하지는 못함.)
    -   전체 학습 과정 시각화:
        ![학습 결과](results/06_01_result.png)
-   **원인 분석**:

    **1. 절대적으로 부족한 학습 시간 및 컴퓨팅 자원의 한계**
    -   RTX 4070 GPU 환경에서 1 에폭을 학습하는 데 약 2시간 30분이 소요되어, 현실적인 시간 제약으로 인해 총 **20 에폭**밖에 학습을 진행하지 못했습니다. 복잡하고 다양한 객체가 존재하는 BDD100K 데이터셋의 특징을 완전히 학습하기에는 절대적으로 부족한 시간이었습니다.

    **2. 제안한 구조의 잠재적 역효과: "쉬운 신호"에만 집중하는 어텐션**
    -   짧은 학습 기간(20 에폭) 동안, Stage 3에 적용된 `DWConv3x3_7x7_Attn` 모듈의 어텐션 메커니즘이 최적의 전략을 찾지 못하고, 가장 학습하기 **쉽고 강한 신호에만 집중하는 "지름길"을 택했을 가능성**이 있습니다.
    -   객체 탐지에서 '쉽고 강한 신호'는 보통 **'큰(Large) 객체'**에 해당합니다. 큰 객체는 이미지에서 차지하는 픽셀 수가 많고, 형태나 특징이 명확하여 모델이 초기에 더 쉽게 학습할 수 있습니다. 반면, 작고 세부적인 특징을 가진 '작은(Small) 객체'는 학습하기 훨씬 어렵습니다.
    -   이 가설은 아래의 객체 크기별 mAP 점수 분석 결과와 일치합니다. **큰 객체에 대한 mAP(0.23)는 상대적으로 높게 나타난 반면, 작은 객체에 대한 mAP(0.029)는 거의 탐지를 못하는 수준으로 처참하게 낮았습니다.** 이는 모델이 어려운 작은 객체들을 효과적으로 학습하지 못하고, 쉽고 점수를 얻기 좋은 큰 객체에만 집중했음을 시사합니다.

        ![객체 크기별 mAP 분석](results/map_by_size.png)

-   **결론 및 다음 단계**:
    -   현재의 낮은 성능은 제안한 구조의 문제라기보다는 **불충분한 학습**이 가장 큰 원인으로 판단됩니다.
    -   **다음 단계 1 (최우선)**: 학습 안정성과 시간을 고려하여, 최소 50 에폭 이상으로 학습을 연장하여 모델이 BDD100K 데이터셋의 복잡한 패턴을 충분히 학습할 시간을 제공해야 합니다.
    -   **다음 단계 2**: 충분한 학습 후에도 작은 객체에 대한 성능이 개선되지 않는다면, Stage 3의 어텐션 구조가 오히려 저해상도(작은 객체) 특징 학습을 방해한다는 가설을 세우고, 해당 모듈을 더 단순한 구조로 변경하거나 제거하는 실험을 진행할 필요가 있습니다.
